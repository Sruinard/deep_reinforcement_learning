{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import agent\n",
    "import environment\n",
    "\n",
    "import jax.random as jrandom\n",
    "import jax.numpy as jnp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.setdefault('JAX_PLATFORM_NAME', 'gpu')     # tell JAX to use GPU\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.7'  # don't use all gpu mem\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_frames_processed_per_second(step_idx, time_to_start_training):\n",
    "    time_taken_until_training = time.time() - time_to_start_training\n",
    "    return step_idx / time_taken_until_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "env = environment.create(\"PongNoFrameskip-v4\")\n",
    "REWARD_BOUND_TO_SOLVE_PONG = 19.5\n",
    "MINIMUM_REPLAY_BUFFER_SIZE = 64\n",
    "SYNC_EVERY_N_STEPS = 1000\n",
    "\n",
    "\n",
    "model_hparams = agent.ModelHParams()\n",
    "agent_hparams = agent.AgentHParams()\n",
    "net = agent.Agent(\n",
    "    model_architecture=agent.Brain,\n",
    "    model_hparams=model_hparams,\n",
    "    agent_hparams=agent_hparams,\n",
    "    n_actions=env.action_space.n,\n",
    ")\n",
    "target_net = agent.Agent(\n",
    "    model_architecture=agent.Brain,\n",
    "    model_hparams=model_hparams,\n",
    "    agent_hparams=agent_hparams,\n",
    "    n_actions=env.action_space.n,\n",
    ")\n",
    "rng = jrandom.PRNGKey(net.seed)\n",
    "\n",
    "observation, _ = env.reset()\n",
    "batch = jnp.expand_dims(observation, axis=0)\n",
    "state = net.initialize(batch)\n",
    "target_state = target_net.initialize(batch)\n",
    "\n",
    "average_loss = []\n",
    "total_reward = 0\n",
    "total_rewards = []\n",
    "best_reward = 0\n",
    "step_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_start_training = time.time()\n",
    "epsilon = 0.0\n",
    "for _ in range(100):\n",
    "    action = agent.policy(state, observation, env.action_space.n, epsilon, action_rng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_start_training = time.time()\n",
    "for _ in range(100):\n",
    "    train_batch = net.get_batch(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_start_training = time.time()\n",
    "for _ in range(100):\n",
    "    agent.train_step(train_batch, state, target_state, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(100):\n",
    "    idxs = net.memory.get_batch_idxs(32, rng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    states, actions, rewards, is_dones, next_states = zip(*[dataclasses.asdict(net.memory.memory[idx]).values() for idx in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    return_value = (\n",
    "            jnp.asarray(states, dtype=jnp.float32), \n",
    "            jnp.asarray(actions), \n",
    "            jnp.asarray(rewards, dtype=jnp.float32), \n",
    "            jnp.asarray(is_dones, dtype=jnp.uint8), \n",
    "            jnp.asarray(next_states, dtype=jnp.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_start_training = time.time()\n",
    "epsilon = 0.0\n",
    "for step_idx in range(1000):\n",
    "    action = agent.policy(state, observation, env.action_space.n, epsilon, action_rng)\n",
    "    next_observation, reward, is_done, *_ = env.step(action)\n",
    "    if is_done:\n",
    "        next_observation, _ = env.reset()\n",
    "    observation = next_observation\n",
    "    train_batch = net.get_batch(rng)\n",
    "    agent.train_step(train_batch, state, target_state, 0.99)\n",
    "\n",
    "end_time = time.time()\n",
    "fps = step_idx / (end_time - time_to_start_training)\n",
    "print(fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken until training: 30.113\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "# jax.profiler.start_server(9999)\n",
    "total_reward = 0\n",
    "best_reward = -100\n",
    "step_idx = 0\n",
    "episode_id = 0\n",
    "time_to_start_training = time.time()\n",
    "\n",
    "is_log_start_training = True\n",
    "\n",
    "log_dir = \"./log_dir/tensorboard/\"\n",
    "\n",
    "for _ in range(200):\n",
    "    \n",
    "    step_idx += 1\n",
    "    rng, action_rng = jrandom.split(rng)\n",
    "    epsilon = net.get_epsilon(step_idx=step_idx)\n",
    "    time_to_execute_policy = time.time()\n",
    "    with jax.profiler.trace(log_dir=log_dir):\n",
    "        action = agent.policy(state, observation, env.action_space.n, epsilon, action_rng)\n",
    "    with jax.profiler.trace(log_dir=log_dir):\n",
    "        next_observation, reward, is_done, *_ = env.step(action)\n",
    "    net.memory.add_experience_to_memory(observation, action, reward, is_done, next_observation)\n",
    "    time_taken_to_execute_policy = time.time() - time_to_execute_policy\n",
    "    total_reward += reward\n",
    "    if is_done:\n",
    "        episode_id += 1\n",
    "        print(\"time taken to execute policy: %.3f\" % time_taken_to_execute_policy)\n",
    "        print(\"episode: %d, total steps: %d, reward: %.3f, best reward: %.3f, epsilon: %.2f\" % (episode_id, step_idx, total_reward, best_reward, epsilon))\n",
    "        print(\"number of frames processed per second: %.3f\" % number_of_frames_processed_per_second(step_idx, time_to_start_training))\n",
    "        next_observation, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        if net.memory_size > MINIMUM_REPLAY_BUFFER_SIZE:\n",
    "            print(\"time taken for training step: %.3f\" % (time_train_step_end - time_train_step_start))\n",
    "\n",
    "    observation = next_observation\n",
    "\n",
    "    if net.memory_size < MINIMUM_REPLAY_BUFFER_SIZE:\n",
    "        continue\n",
    "\n",
    "    if is_log_start_training:\n",
    "        time_taken_until_training = time.time() - time_to_start_training\n",
    "        # print time taken until training in seconds\n",
    "        print(\"time taken until training: %.3f\" % time_taken_until_training)\n",
    "        is_log_start_training = False\n",
    "\n",
    "    if step_idx % SYNC_EVERY_N_STEPS == 0:\n",
    "        target_state = agent.sync_target_network(state=state, target_state=target_state)\n",
    "\n",
    "\n",
    "    with jax.profiler.trace(log_dir=log_dir):\n",
    "\n",
    "        rng, batch_rng = jrandom.split(rng)\n",
    "        loss, state, rng = net.train_step(state=state, target_state=target_state, rng=rng)\n",
    "        time_train_step_end = time.time()\n",
    "        loss.block_until_ready()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 04:57:25.632052: W external/org_tensorflow/tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-01-02 04:57:25.642136: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:192] cuptiSubscribe: error 15: CUPTI_ERROR_NOT_INITIALIZED\n",
      "2023-01-02 04:57:25.642158: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-01-02 04:57:25.642167: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1715] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-01-02 04:57:25.780546: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:497] The NVIDIA driver's CUDA version is 11.4 which is older than the ptxas CUDA version (12.0.76). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "2023-01-02 04:57:25.789796: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 3.7\n",
      "2023-01-02 04:57:25.789824: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-01-02 04:57:41.242384: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gemm_algorithm_picker.cc:219] Failed to find best cuBLAS algorithm, GEMM performance might be suboptimal: INTERNAL: All algorithms tried for %cublas-gemm.1 = f32[5000,5000]{1,0} custom-call(f32[5000,5000]{1,0} %Arg_0.1, f32[5000,5000]{1,0} %Arg_1.2), custom_call_target=\"__cublas$gemm\", metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_490322/2340755601.py\" source_line=6}, backend_config=\"{\\\"alpha_real\\\":1,\\\"alpha_imag\\\":0,\\\"beta\\\":0,\\\"dot_dimension_numbers\\\":{\\\"lhs_contracting_dimensions\\\":[\\\"1\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"],\\\"lhs_batch_dimensions\\\":[],\\\"rhs_batch_dimensions\\\":[]},\\\"precision_config\\\":{\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\"}\" failed. Falling back to default algorithm.  Per-algorithm errors:\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "2023-01-02 04:57:41.496268: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2023-01-02 04:57:41.496316: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-01-02 04:57:41.496326: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1807] function cupti_interface_->Finalize()failed with error \n",
      "2023-01-02 04:57:41.523637: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-01-02 04:57:41.523669: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "with jax.profiler.trace(log_dir=\"./logdir/default\"):\n",
    "  key = jax.random.PRNGKey(0)\n",
    "  x = jax.random.normal(key, (5000, 5000))\n",
    "  y = x @ x\n",
    "  y.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 05:03:25.471636: W external/org_tensorflow/tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/intel64/lib:/opt/intel/compilers_and_libraries_2018.3.222/linux/mpi/mic/lib::/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64/\n",
      "2023-01-02 05:03:25.481410: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:192] cuptiSubscribe: error 15: CUPTI_ERROR_NOT_INITIALIZED\n",
      "2023-01-02 05:03:25.481429: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-01-02 05:03:25.481437: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1715] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-01-02 05:03:25.619214: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:497] The NVIDIA driver's CUDA version is 11.4 which is older than the ptxas CUDA version (12.0.76). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "2023-01-02 05:03:25.629524: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 3.7\n",
      "2023-01-02 05:03:25.629555: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-01-02 05:03:26.873417: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/gemm_algorithm_picker.cc:219] Failed to find best cuBLAS algorithm, GEMM performance might be suboptimal: INTERNAL: All algorithms tried for %cublas-gemm.1 = f32[5000,5000]{1,0} custom-call(f32[5000,5000]{1,0} %Arg_0.1, f32[5000,5000]{1,0} %Arg_1.2), custom_call_target=\"__cublas$gemm\", metadata={op_name=\"jit(matmul)/jit(main)/dot_general[dimension_numbers=(((1,), (0,)), ((), ())) precision=None preferred_element_type=None]\" source_file=\"/tmp/ipykernel_500764/2885799985.py\" source_line=6}, backend_config=\"{\\\"alpha_real\\\":1,\\\"alpha_imag\\\":0,\\\"beta\\\":0,\\\"dot_dimension_numbers\\\":{\\\"lhs_contracting_dimensions\\\":[\\\"1\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"],\\\"lhs_batch_dimensions\\\":[],\\\"rhs_batch_dimensions\\\":[]},\\\"precision_config\\\":{\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"]},\\\"epilogue\\\":\\\"DEFAULT\\\"}\" failed. Falling back to default algorithm.  Per-algorithm errors:\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "2023-01-02 05:03:26.999041: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2023-01-02 05:03:26.999086: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-01-02 05:03:26.999095: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1807] function cupti_interface_->Finalize()failed with error \n",
      "2023-01-02 05:03:27.019795: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-01-02 05:03:27.019826: E external/org_tensorflow/tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid trace folder: /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-deeprl/code/Users/stefruinard/deep_reinforcement_learning/003_dqn_pong/logdir/jax-trace/plugins/profile/2023_01_02_05_03_27",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m x \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(key, (\u001b[39m5000\u001b[39m, \u001b[39m5000\u001b[39m))\n\u001b[1;32m      6\u001b[0m y \u001b[39m=\u001b[39m x \u001b[39m@\u001b[39m x\n\u001b[0;32m----> 7\u001b[0m y\u001b[39m.\u001b[39mblock_until_ready()\n",
      "File \u001b[0;32m/anaconda/envs/deeprl/lib/python3.9/contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/deeprl/lib/python3.9/site-packages/jax/_src/profiler.py:237\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(log_dir, create_perfetto_link, create_perfetto_trace)\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[39myield\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m   stop_trace()\n",
      "File \u001b[0;32m/anaconda/envs/deeprl/lib/python3.9/site-packages/jax/_src/profiler.py:198\u001b[0m, in \u001b[0;36mstop_trace\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m _profile_state\u001b[39m.\u001b[39mprofile_session\u001b[39m.\u001b[39mstop_and_export(_profile_state\u001b[39m.\u001b[39mlog_dir)\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m _profile_state\u001b[39m.\u001b[39mcreate_perfetto_trace:\n\u001b[0;32m--> 198\u001b[0m   abs_filename \u001b[39m=\u001b[39m _write_perfetto_trace_file(_profile_state\u001b[39m.\u001b[39;49mlog_dir)\n\u001b[1;32m    199\u001b[0m   \u001b[39mif\u001b[39;00m _profile_state\u001b[39m.\u001b[39mcreate_perfetto_link:\n\u001b[1;32m    200\u001b[0m     _host_perfetto_trace_file(abs_filename)\n",
      "File \u001b[0;32m/anaconda/envs/deeprl/lib/python3.9/site-packages/jax/_src/profiler.py:135\u001b[0m, in \u001b[0;36m_write_perfetto_trace_file\u001b[0;34m(log_dir)\u001b[0m\n\u001b[1;32m    133\u001b[0m trace_jsons \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(latest_folder, \u001b[39m\"\u001b[39m\u001b[39m*.trace.json.gz\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trace_jsons) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid trace folder: \u001b[39m\u001b[39m{\u001b[39;00mlatest_folder\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    136\u001b[0m trace_json, \u001b[39m=\u001b[39m trace_jsons\n\u001b[1;32m    138\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mLoading trace.json.gz and removing its metadata...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid trace folder: /mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-deeprl/code/Users/stefruinard/deep_reinforcement_learning/003_dqn_pong/logdir/jax-trace/plugins/profile/2023_01_02_05_03_27"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "with jax.profiler.trace(\"./logdir/jax-trace\", create_perfetto_link=True):\n",
    "  # Run the operations to be profiled\n",
    "  key = jax.random.PRNGKey(0)\n",
    "  x = jax.random.normal(key, (5000, 5000))\n",
    "  y = x @ x\n",
    "  y.block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Time taken to execute one episode: 139.725\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "env.reset()\n",
    "i = 0\n",
    "while True:\n",
    "    i+=1\n",
    "    action = agent.policy(state, observation, env.action_space.n, 0.01, action_rng)\n",
    "    observation, reward, is_done, *_ = env.step(env.action_space.sample())\n",
    "    if is_done:\n",
    "        print(\"done\")\n",
    "        env.reset()\n",
    "        end_time = time.time()\n",
    "        break\n",
    "    loss, state, rng = net.train_step(state=state, target_state=target_state, rng=rng)\n",
    "print(\"Time taken to execute one episode: %.3f\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.228485958879105"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i / (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.480"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "539d3ffc0899d5f2f8fa8c5db4efce0fd8570b61b77531839d8b3674c13af9c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
